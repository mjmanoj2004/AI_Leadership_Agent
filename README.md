# ğŸš€ AI Leadership Insight & Autonomous Decision Agent

Modular AI system with two distinct agents:

1. **Insight Agent** â€“ RAG-based agent that answers factual questions from internal company documents (Chroma + sentence-transformers).
2. **Strategic Decision Agent** â€“ LangGraph workflow:
   - Question Analysis  
   - Internal Research  
   - Knowledge Gap Detection  
   - Strategic Options Generation  
   - Risk Assessment  
   - Decision Synthesis (recommendations + confidence)

---

# ğŸ§± Tech Stack

- **Python 3.11
- **Backend:** FastAPI
- **UI:** Streamlit
- **LLM Orchestration:** LangChain + LangGraph
- **LLM:** HuggingFace (configurable free model)
- **Embeddings:** sentence-transformers
- **Vector DB:** Chroma (Hybrid Search: Semantic + BM25 + RRF)
- **Document Monitoring:** watchdog

---

# ğŸ“ Project Structure

```
AI_Leadership_Agent/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ llm/
â”‚   â””â”€â”€ models/
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ ingest_documents.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/
â”‚   â””â”€â”€ chroma_db/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_api.py
â”œâ”€â”€ run_ui.py
â””â”€â”€ README.md
```

---

# âš™ï¸ Setup

## 1ï¸âƒ£ Create Virtual Environment (Python 3.11)

### Windows

```bash
py -3.11 -m venv .venv
.venv\Scripts\activate
```

### Mac / Linux

```bash
python3.11 -m venv .venv
source .venv/bin/activate
```

---

## 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## 3ï¸âƒ£ Configure Environment

Copy example file:

```bash
cp .env.example .env
```

Edit `.env` and set:

```
HUGGINGFACE_HUB_TOKEN=your_token_here
```

Get your token from:
https://huggingface.co/settings/tokens

Enable:
- Read access
- Inference API / Inference Providers

Without a valid token:
- AI summaries will fail
- You may see â€œmodel unavailableâ€ errors

---

## 4ï¸âƒ£ Ingest Company Documents (Recommended)

Place PDF / DOCX / TXT files in:

```
data/documents/
```

Run:

```bash
python scripts/ingest_documents.py
```

If you change chunking strategy, re-run ingestion.

### Upload via UI

You can also upload documents through the Streamlit sidebar.  
Files are automatically saved and ingested.

---

# â–¶ï¸ Running the Application

## Start Backend (FastAPI)

```bash
uvicorn src.api.main:app --reload
```

API:
```
http://localhost:8000
```

Docs:
```
http://localhost:8000/docs
```

---

## Start UI (Streamlit)

```bash
streamlit run ui/app.py
```

UI:
```
http://localhost:8502
```

---

# ğŸ§  Using the System

### Modes

- **Auto** â€“ Classifier chooses agent
- **Insight** â€“ RAG-based factual answers
- **Strategic** â€“ Full Decision Agent workflow

### Example Questions

Insight:
```
What is our revenue trend over the last 3 years?
```

Strategic:
```
Should we expand into Southeast Asia?
```

Outputs include:
- Answer
- Sources
- Reasoning trace (expandable)
- Risk chart (strategic mode)

---

# ğŸ”Œ API

## POST `/ask`

### Request

```json
{
  "question": "Your question here",
  "mode": "auto | insight | strategic"
}
```

### Response

```json
{
  "agent_type": "insight | strategic",
  "answer": "...",
  "sources": [
    { "content": "...", "metadata": {}, "score": 0.9 }
  ],
  "reasoning_trace": [
    { "node": "...", "summary": "..." }
  ],
  "risk_summary": {
    "options": [],
    "scores": {}
  }
}
```

---

# ğŸ§© Strategic Decision Agent (LangGraph)

Workflow:

1. Question Analyzer  
2. Internal Research  
3. Knowledge Gap Detection  
4. Strategic Reasoning  
5. Risk Assessment  
6. Decision Synthesis  

If context is insufficient, the graph loops back to Internal Research (configurable max iterations).

---

# ğŸ” Hybrid Retrieval System

Retrieval uses **Hybrid Search**:

### 1ï¸âƒ£ Semantic Search
- Chroma similarity search  
- Top 5 embedding matches  

### 2ï¸âƒ£ Keyword Search
- BM25 over stored chunks  
- Top 5 keyword matches  

### 3ï¸âƒ£ Fusion
- Reciprocal Rank Fusion (RRF, k=60)  
- Final Top 5 combined chunks  

Hybrid can be disabled:

```python
query_documents(use_hybrid=False)
```

---

# ğŸ”§ Extensibility - For Production Grade

You can extend the system by:

- Adding new tools (web search, forecasting, financial analysis)
- Introducing memory or multi-agent collaboration
- AWS - S3 bucket for documents, API gateway, Rate limiting, 
- LLM - any better/latest/Fine tuned/ vLLM can be used
- Vector DB - Any other managed vector db is better option for production grade applications
- Token usage monitoring can be done
- Observability can be included e.g. langsmith
- Access - JWT token, Role based access to upload documents
- Gaurdrails
- Redis cache
- Async processing
- connection pooling
- Docker, K8s
---




